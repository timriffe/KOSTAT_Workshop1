---
title: | 
  | \includegraphics{logotip.pdf}
  |
  | KOSTAT-UNFPA Summer Seminar on Population
  | \vspace{1.5cm} \LARGE \emph{Workshop~1.~Introduction to Demography}
  | \vspace{0.3cm} \huge \textbf{Day 2: Mortality and Fertility}\vspace{0.6cm}
  | 
fontsize: 11pt
geometry: a4paper, twoside, left=2.5cm, right=2.5cm, top=2cm, bottom=2.8cm, headsep
  = 1.35cm, footskip = 1.6cm
output:
  pdf_document:
    number_sections: yes
  html_document2: default
  html_document:
    number_sections: yes
    toc: yes
  pdf_document2: default
  header-includes:
    - \usepackage{titling}
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead[LE]{\thepage~\qquad~KOSTAT-UNFPA Summer Seminar on Population}
    - \fancyhead[RE]{Workshop~1.~Introduction to Demography}
    - \fancyhead[LO]{{Day 2: Mortality and Fertility}}
    - \fancyhead[RO]{Tim Riffe\qquad~\thepage}
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\noindent\makebox[\textwidth][c]{
  \begin{minipage}[t]{0.8\textwidth}
    \centering
    \Large{Instructor: \\ Tim Riffe \texttt{tim.riffe@ehu.eus}\\}
    \vspace{.5cm}
    \Large{Assistant: \\ Inchan Hwang \texttt{inchanhwang@utexas.edu }}
  \end{minipage}
}


\vspace{0.8cm}
\begin{center}
\large{24 June 2025}
\end{center}
\vspace{0.8cm}


\tableofcontents

# Mortality

Mortality sets a fundamental constraint on population well-being by defining a longevity envelope within which all life happens. Mortality levels vary over age by orders of magnitude, and can also vary between populations. Demography delivers tools to understand mortality levels in terms of metrics in different units, and to adjust these metrics to be able to make valid comparisons between populations. The lifetable is the basic analytic tool to allow for valid and comparable summary metrics at the population level.

## Lifetable transformations as functions

I describe the lifetable together with function-writing because lifetable transformations give simple practice in functionalizing mathematical formulas. When function-writing, it is desirable to work with test data handy. For this, go ahead and load the`KOR2014` file from yesterday like so:

```{r, message = FALSE, warning=FALSE}
library(tidyverse)
KOR2014 <- read_csv("Data/KOR2014.csv",
                    show_col_types = FALSE)
```

We will take what we need from this file as we go.

## Death probabilities between age $x$ and $x+n$ $_nq_x$

The first and key step is to transform a set of age-specific death rates into a set of age-specific probabilities of dying (${}_nq_x$). The relationship between ${}_nM_x$ and ${}_nq_x$ has been established based on analyses of actual cohorts (for mathematical proof, see @preston2001demography, p. 42-43). 

$$
{}_nq_x = \frac{n\cdot{}_nM_x}{1+(n-{}_nA_x)\cdot{}_nM_x}
$$
where $_nA_x$ is the average number of person-years lived in the interval by those dying in the interval and $n$ is the width of the age-interval.

For single ages or when we're pragmatic, we define ${}_nA_x = n/2$ with the exceptions of the first and the last age group. Other approximations are also available, but these only matter when age groups are wider than a year. In our case, we're working with abridged lifetables, some of which represent high mortality settings, and the ${}_nA_x$ assumptions are consequential. In our case, I provide this value so that we don't need to work so hard at deriving it in class. You could find several popular ${}_nA_x$ approximations in the `DemoTools` package @DemoTools.

Getting down to business, we can rather directly convert the ${}_nq_x$ formula to an `R` function: 

```{r}
calc_nqx <- function(nMx, nAx, n){
  qx         <- (n * nMx) / (1 - (n - nAx) * nMx)
  
  # these are kludges, necessary to ensure nqx results as a probability
  qx[qx > 1] <- 1
  qx[qx < 0] <- 0
  qx
}
```

Here's how we can use this function in tidyverse syntax and plot the result:
```{r}
# Example of what nqx looks like over age
KOR2014 |> 
  filter(sex == "total") |> 
  mutate(nMx = deaths / exposure,
         nAx = if_else(age == 0, .1, .5),
         n = 1,
         nqx = calc_nqx(nMx = nMx, nAx = nAx, n = n)) |> 
  ggplot(aes(x = age, y = nqx)) + 
  geom_line() +
  scale_y_log10() +
  labs(title = "nqx Korea, 2014",
       subtitle = "Data: HMD") +
  theme_minimal()
```
Often we're sure to *close out* the lifetable by making the *final* ${}_nq_x$ value equal to 1. You could optionally modify the function to impute 1 like so `nqx[length(nqx)] <- 1`.

<!-- Actually in this data, we see the classic formula for $q(x)$ conversion sort of breaks down in the oldest ages, arriving at $q(x)$ values greater than 1. I find this annoying, and this compels me to implement a different approach to getting $q(x)$ for wide intervals: -->

<!-- Observe the following pathological case: -->
<!-- ```{r} -->
<!-- # annoying kluge here: -->
<!-- calc_nqx(.21, 2, 5) -->
<!-- # however if we were in single ages this nMx value would give no problems: -->
<!-- calc_nqx(.21, 2/5, 1) -->
<!-- # and this can be brought to a 5-year nqx under a constant probability assumption: -->
<!-- 1 - (1 - calc_nqx(.21, 2/5, 1))^5 -->
<!-- # quite a reasonable value -->
<!-- ``` -->
<!-- That is, if we assume a constant rate in the interval ($n$), we have an implied single-age $q_x$ of: -->

<!-- $$ {}_1q_x = \frac{{}_nM_x}{1 + (1 - \frac{{}_nA_x}{n}) \cdot{}_nM_x} $$ -->
<!-- The compliment of the $n^{th}$ power of its compliment (cumulative survival in the interval) can then be got as: -->

<!-- $$ {}_nq_x = 1 - (1 - {}_1q_x)^n$$ -->

<!-- Here is the alternative conversion approach as an `R` function: -->
<!-- ```{r} -->
<!-- calc_nqx_v2 <- function(nMx, nAx, n){ -->
<!--   qx1              <- (nMx) / (1 - (1 - nAx / n) * nMx) -->
<!--   # the complement of the cumulative survival product... -->
<!--   nqx              <-  1 - (1 - qx1) ^ n -->
<!--   # these are kludges, necessary to ensure nqx results as a probability -->
<!--   nqx[nqx > 1]     <- 1 -->
<!--   nqx[nqx < 0]     <- 0 -->
<!--   # closeout qx! -->
<!--   nqx[length(nqx)] <- 1 -->
<!--   nqx -->
<!-- } -->
<!-- ``` -->

<!-- I suggest we use this second version for purely pragmatic reasons with these data, unless someone comes along and tells me what's going on with the standard formula, or an error is detected somewhere else. A possibility which I've not explored is that the GHO's delivered `nMx` and `nqx` values are not aligned so as to give an accurate `nAx`. It's possible, but it shouldn't be that way.  -->

Note, this $q(x)$ formula does not necessarily need to be committed to memory. This is something we either derive or look up as needed. For our needs we are satisfied with our values of $q(x)$, $m(x)$ and $a(x)$, and the remainder of the lifetable is now determined.

## Survival probabilities between age $x$ and $x+n$, $_np_x$

The survival probabilities between age $x$ and $x+n$ (${}_np_x$) is simply one minus ${}_nq_x$. It is interpreted as the chance of surviving from age $x$ to age $x+n$.

$$
{}_np_x = 1 - {}_nq_x
$$
Really there's no need to program a function for this column, as we can just use ${}_nq_x$ as the function argument and take its complement as needed.

## Survival probabilities to age $x$, $l_x$

This lifetable column indicates the chance of surviving from birth to age x ($l_x$) OR the number of survivors at age $x$ relative to the radix $r$ of the life table. The $l_0=r$ is interpreted as the initial size of the synthetic lifetable population, generally set to 1 or 100,000. Think of this as the number of *sims* in your lifetable. Here's one of several ways to calculate it given what we have so far:
$$
l_{x+n} = r \prod_{y=0}^x {}_np_y
$$
where $r = {}_nl_0$ is the radix. To program this, our arguments should be ${}_nq_x$ (`nqx`) or ${}_np_x$ (`npx`) and `radix`. In this case, we can assign a default value for the radix when defining the function using `radix = 1`. Whenever the argument isn't specified by the user, 1 will be assumed.

```{r}
# nqx is a full vector over age.
calc_lx <- function(nqx, radix = 1){
  npx <- 1 - nqx
  n   <- length(nqx)
  lx  <- cumprod(npx)
  # shift it back 1, as we start with 100%!
  # also ensure outgoing vector is the same length.
  lx  <- radix * c(1, lx[-n])
  lx
}
```

And here is an application of the new function to data, as per before:
```{r}
KOR2014 |> 
  filter(sex == "total") |> 
  mutate(nMx = deaths / exposure,
         nAx = if_else(age == 0, .1, .5),
         n = 1,
         nqx = calc_nqx(nMx = nMx, nAx = nAx, n = n),
         lx = calc_lx(nqx = nqx)) |> 
  ggplot(aes(x = age, y = lx)) + 
  geom_line() +
  ylim(0,1) +
  labs(title = "lx Korea, 2014",
       subtitle = "Data: HMD") +
  theme_minimal()
```


## Death distribution, $_nd_x$

The life table deaths (${}_nd_x$) is the number of (synthetic) persons dying between age $x$ and $x+n$, relative to the radix, and represents the distribution of deaths over age. There are two ways of calculating ${}_nd_x$. When programming, this is the most pragmatic way of calculating it:

$$
{}_nd_x = {}_nq_x * l_x
$$
One could ask, do we really need this function? This is something we can remember, right?
```{r}
calc_ndx <- function(nqx, lx){
   nqx * lx
}
```

## Person-years lived between age $x$ and $x+n$, $_nL_x$

The number of person-years between age $x$ and $x+n$ (${}_nL_x$) is calculated as:

$$
{}_nL_x = n(l_{x} - {}_nd_x) + {}_na_x\cdot{}_nd_x \\
$$
$$
= n \cdot l_x - (n - {}_na_x) _nd_x
$$
**Note**

${}_nm_x = {}_nd_x/{}_nL_x$

and 

${}_nq_x = {}_nd_x/l_x$

```{r}
calc_nLx <- function(lx, ndx, nAx, n){
  N        <- length(lx)
  nLx      <- n[-N] * lx[-1] + nAx[-N] * ndx[-N]
  # special treatment for open age
  nLx[N]	 <- lx[N] * nAx[N] 
  nLx
}

# and application with no plot:
KOR2014 |> 
  filter(sex == "total") |> 
  mutate(nMx = deaths / exposure,
         nAx = if_else(age == 0, .1, .5),
         n = 1,
         nqx = calc_nqx(nMx = nMx, nAx = nAx, n = n),
         lx = calc_lx(nqx = nqx),
         ndx = lx * nqx,
         nLx = calc_nLx(lx = lx, ndx = ndx, nAx = nAx, n = n)) |> 
  head()
```

## Person-years lived above age x $T_x$

Calculating the number person-years lived above age x ($T_x$) is a key step to calculate life expectancy. It consists in finding the sum of $_nL_x$ from age x:

$$
T_x = \sum_{y=x}^{\infty} {}_nL_y
$$

```{r}
calc_Tx <- function(nLx){
  # to understand this, look at the nLx curve,
  # then imagine integrating from the right 
  # to the left. Then compare with the formula!
  nLx |> 
    rev() |> 
    cumsum() |> 
    rev()
}
```

## Life expectancy $e_x$

The last indicator in the life table is probably one of the most used in demographic analysis. The life expectancy is the average number of years lived by a (synthetic) cohort reaching age x. It consists in dividing the number of person-years lived above age x by the number of people alive at age x:  

$$
e_x = \frac{T_x}{l_x}
$$
Since `mutate()` let's you make columns in a sequentially dependent way, we can actually do this whole lifetable inside a single `mutate()` statement. However, each combination of `Year` and `Sex` is an independent lifetable, so we need to declare groups beforehand using `group_by()`:

```{r}
calc_ex <- function(Tx, lx){
  Tx / lx
}

KOR2014 |> 
  filter(sex == "total") |> 
  mutate(nMx = deaths / exposure,
         nAx = if_else(age == 0, .1, .5),
         n = 1,
         nqx = calc_nqx(nMx = nMx, nAx = nAx, n = n),
         lx = calc_lx(nqx = nqx),
         ndx = lx * nqx,
         nLx = calc_nLx(lx = lx, ndx = ndx, nAx = nAx, n = n),
         Tx = calc_Tx(nLx = nLx),
         ex = calc_ex(Tx = Tx, lx = lx)) |> 
  filter(age == 0) |> 
  pull(ex)
```

## Calculating a lifetable for grouped data

If your data has many subgroups, we can calculate a lifetable for each of them by declaring groups on the data object with `group_by()`:
```{r}
KOR2014 |> 
  group_by(sex) |> 
  mutate(nMx = deaths / exposure,
         nAx = if_else(age == 0, .1, .5),
         n = 1,
         nqx = calc_nqx(nMx = nMx, nAx = nAx, n = n),
         lx = calc_lx(nqx = nqx),
         ndx = lx * nqx,
         nLx = calc_nLx(lx = lx, ndx = ndx, nAx = nAx, n = n),
         Tx = calc_Tx(nLx = nLx),
         ex = calc_ex(Tx = Tx, lx = lx)) |> 
  ungroup() |> 
  filter(age == 0) |> 
  select(sex, ex)
```

# A Lifetable function

You probably noticed that a whole lifetable operation can fit in a single `mutate()` call! Note, you could calculate all lifetables for each subset by simply including a `group_by()`. Well, that may be so, but there's still value in creating a wrapper function that does the whole thing:

```{r}
calc_LT <- function(nMx, nAx, n, radix){
  N <- length(nMx)
  nqx  <- calc_nqx(nMx, nAx, n)
  lx   <- calc_lx(nqx = nqx, radix = 1)
  ndx  <- calc_ndx(nqx = nqx, lx = lx)
  nLx  <- calc_nLx(lx = lx, ndx = ndx, nAx = nAx, n = n)
  Tx   <- calc_Tx(nLx = nLx)
  ex   <- calc_ex(Tx = Tx, lx = lx)
  Age  <- cumsum(c(0,n))[1:N]
  
  
  tibble(Age = Age,
         nMx = nMx,
         nAx = nAx,
         nqx = nqx,
         lx = lx,
         ndx = ndx,
         nLx = nLx,
         Tx = Tx,
         ex = ex)
}
```

This function can be used as-is in a tidy pipeline using the `reframe()` verb. `reframe()` is like a more flexible version of `mutate()` or `summarize()`. The issue is here we have a function that takes vectors as its arguments, but returns a whole `data.frame` as its output.
```{r}
KOR2014 |> 
  mutate(nMx = deaths / exposure,
         nAx = case_when(age == 0 ~ .1,
                         age == 110 ~ 1/nMx,
                         TRUE ~ .5),
         n = 1) |> 
  reframe(calc_LT(nMx,nAx,n, radix = 100000)) |> 
  head()
```


## reformulate as `data.frame`-in `data.frame`-out

You could also set the function up to work in a tidy pipeline by making a function that takes a whole data.frame as its input, and that also returns a data.frame. we'll just want to be sure that the input consists in a whole group (or chunk) of data:
```{r}
# data.frame in, data.frame out!
calc_LT_tidy <- function(data, radix){
  # this is hacky, but works.
  # just pick out the needed vectors from the group of data
  calc_LT(nMx = data$nMx,
          nAx = data$nAx,
          n = data$n,
          radix = radix)
}
```

Now, this is something you can easily apply in bulk using `group_modify()` (`reframe()` also still works here!). You could design this in many different ways actually. 

```{r}
KOR2014 |> 
  mutate(nMx = deaths / exposure,
         # You might change the way nAx is made...
         nAx = if_else(age == 0, .1, .5),
         n = 1) |> 
  group_by(sex) |> 
  # this also works, but notice we don't use the ~ for reframe,
  # and that the anonymous name of the incoming data is .data ...
  # reframe(calc_LT_tidy(data=.data, radix = 1e5))
  group_modify(~calc_LT_tidy(data = .x, radix = 1e5)) |> 
  ungroup()
```

# Fertility

In English, fertility refers to observed births, whereas fecundity refers to the capacity to give birth. The basic elements of fertility data include

* Events: births
* Exposure: every women alive in their reproductive age ( $\approx$ 15 to 50 years old)

Births information most often comes from vital registration systems. This is the case for Korea. Countries without vital registration systems, or with incomplete vital registration rely on survey data to estimate fertility indicators.

## Crude birth rate

The crude birth rate (CBR) is a rough measure of the occurrence/exposure of fertility.

$$
CBR[0,T] = \frac{Number~of~births~in~the~population~between~times~T~and~T+t}{Number~of~person-years~lived~in~the~population~between~times~T~and~T+t}
$$

Does this look familiar? It's just like the crude death rate:
```{r}
# Person-years
KOR2014 |> 
  filter(sex == "total") |> 
  summarize(exposure = sum(exposure),
            births = sum(births, na.rm = TRUE)) |> 
  mutate(CBR = births / exposure)
```
Often CBR is multiplied by 1000, so we'd have $8.58 / 1000$

## General fertility rate

The general fertility rate (GFR) is generally considered a better measure of fertility, as only women in their reproductive ages can give birth, and are thus at risk of experiencing the event. Sometimes the upper age is truncated at 45 rather than 50.

$$
GFR[0,T] = \frac{Number~of~births~in~the~population~between~times~T~and~T+t}{Number~of~person-years~lived~by~women~aged~15~to~50~between~times~T~and~T+t}
$$

This solution looks tricky because births are associated with total sex in our data, but here we need to relate them to women. For this, we use `pivot_wider()` to get all combinations of sex and measure side-by-side, then we shift births to females in `mutate()`, then we pivot the data back to its original form, filter to the desired subset, and calculate the GFR:
```{r}
# Female population
KOR2014_2 <-
  KOR2014 |> 
  select(-deaths) |> 
  pivot_wider(names_from = sex, 
              values_from = c(exposure,births)) |> 
  mutate(births_female = births_total) |> 
  pivot_longer(-c(year,age), 
               names_to = c("measure","sex"), 
               values_to= "value",
               names_sep="_") |> 
  pivot_wider(names_from = "measure",
              values_from="value") |> 
  filter(sex == "female")

KOR2014_2 |> 
  filter(between(age, 15,50)) |> 
  summarize(exposure = sum(exposure),
            births = sum(births)) |> 
  mutate(GFR = births / exposure)

```

That is to say, about $33$ per thousand. The GFR does not give unbiased information, however, as the age structure between ages 15 and 50 can vary wildly between populations, as can the shape and location of fertility rates within this range. Ideally, we would like a measure free of the effects of observed population structure.

## Age-specific fertility rates

As with age-specific death rates, age-specific fertility rates ($F$) are less sensitive to the age structure of the population. This measure provides the rate of giving birth for women age $x$ to $x+n$:


$$
_nF_x[0,T]= \frac{Number~of~births~between~times~T~and~T+t~to~women~aged~x~to~x+n}{Number~of~person-years~lived~by~women~aged~x~to~x+n~between~times~T~and~T+t}
$$
```{r, warning = FALSE}
KOR2014_2 |> 
  mutate(asfr = births / exposure) |> 
  ggplot(aes(x = age, y = asfr)) + 
  geom_line() +
  labs(title = "Age-specific fertility rates (Korea 2014)",
       caption = "Data: derived from HMD exposures, HFD births") +
  xlim(12,55) +
  theme_minimal()

```

There can still be unobserved heterogeneity hiding in this population: age is not the only structural determinant of fertility. For instance, fertility may be considered separately by parity, or for other subpopulations.

## Total fertility rate

The total fertility rate (TFR) is the average number of children a woman would have if she experienced the a particular set of age-specific fertility rates and survived until the end of her reproductive age. "*The TFR is the single most important indicator of fertility*" [@preston2001demography]. It is also the area under the ASFR curve.

$$
TFR[T,T+t]= n \sum_{x=a}^{B-n} {}_nF_x [T,T+t]
$$ 
where $a$ and $B$ are the minimum and maximum age at childbearing.

```{r}

# TFR
KOR2014_2 |> 
  mutate(asfr = births / exposure,
         n = 1) |> # make this 5 if you have 5-year age groups!!
  summarize(tfr = sum(asfr * n))


```

This the most commonly calculated and cited fertility metric, but it is not without criticism. For instance, (i) we should not discount the leverage mortality can have on population reproductivity (although it Korea this bias is very low), (ii) if fertility patterns are changing over time a period TFR may not give the best signal of fertility levels, and (iii) TFR is unfortunately sometimes presented as a target.

## Mean age at childbearing
The mean age at childbearing is not a rate, but is based on the age-specific fertility rates. The mean age at childbearing (MA) is the average age of mothers at childbearing, standardized for the age-structure of the female population at reproductive age [@HFD].

$$
MA[T,T+t] = \frac{\sum_{x=a}^{B-n} \bar{x} * {}_nF_x [T,T+t]}{ \sum_{x=a}^{B-n} {}_nF_x [T,T+t]}
$$
where $\bar{x}$ is the mid-age of interval $x:x+n$, i.e. $\bar{x} = x + n/ 2$.

```{r}

# MA
KOR2014_2 |> 
  mutate(asfr = births / exposure,
         n = 1,
         xbar = age + n / 2) |> 
  summarize(MA = sum(xbar * asfr) / sum(asfr))

```

# Exercises
In practical exercises, we will calculate trends for different populations based on different data.

# References {-}

