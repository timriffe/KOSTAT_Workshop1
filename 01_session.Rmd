---
title: "Session 1 Notes"
author: "Tim Riffe"
date: "2025-06-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# rmarkdown introduction

The stuff at the top is the metadata header, which creates the title, etc. No need to mess with that.
Inside the document, you can have sections, separated using hashes.
The main thing to know how to do is make R chunks:

Ctrl + Alt + i to make an R chunk
Ctril + Enter to execute the line of code where the cursor is
library() is to load packages (that you already have installed)
`<-` is to assign (`=` is the same)
functions always work like `function_name()`
specify arguments using their names, to the extent possible
for more than one argument, use commas to separate them
to see a function help file, type `?function_name`
```{r, message = FALSE}
library(tidyverse)

kor_url <- "https://raw.githubusercontent.com/timriffe/KOSTAT_Workshop1/refs/heads/master/Data/KOR2014.csv"

kor <- read_csv(file = kor_url, show_col_types = FALSE)
# ?read_csv
```

# what's inside the data?

One way to see what's in the data is to examine it in the Environment browser

We first looked at `kor` over the in the environment browser, which shows metadata (expand and collapse w blue button)
We then also opened it by double-clicking in the environment browser
Executing `View(kor)` also opens it in a data viewer (looks like a spreadsheet but it isn't one!)
And other helpers, like `str()` for structure, or
`ncol()`, `nrow()` ask the numbers of columns and rows, respectively...
```{r}
# View(kor)
# str(kor)
# summary(kor)
# head(kor)
# tail(kor)
dim(kor)    
nrow(kor)
ncol(kor)
```

# CBR, CDR

$$CBR = 1000\cdot\frac{\sum births}{\sum exposure}$$

`%>%` or `|>` are both pipes. The shortcut is `Ctrl + Shift + m` (`Cmd + up-thingy+ m`)

When pronouncing a tidy sentence the pipes are pronounced as "and then ..."
Whereas all the other tidy infrastructure can be thought of as verbs.
All the major tidyverse functions are verbs to the extent that the _do_ things to the data:
- `filter()` subsets rows of data- you need to give a logical expression (one that evaluates to `TRUE` or `FALSE`), you can use `==` `>`, `>=` inside `filter()`
`select()` is for selecting columns...
`summarize()` reduces rows based on some arbitrary operation, which in our case is aggregation. We collapse 111 rows to 1.
`mutate()` does not change the nr of rows; it can change columns or create new ones.
```{r}
CBR <-
  kor |> 
  select(-year) |> 
  filter(sex == "total") |> 
  summarize(B = sum(births),
            E = sum(exposure)) |> 
  mutate(CBR = 1000 * B / E)
CBR
```

# Exercise: calculate CDR
$$ CDR = 1000 \cdot \frac{\sum deaths}{\sum exposure}$$

```{r}
kor |> 
  filter(sex == "total") |> 
  summarize(D = sum(deaths),
            B = sum(births),
            E = sum(exposure)) |> 
  mutate(CDR = 1000 * D / E,
         CBR = 1000 * B / E)
```

# GFR 
General Fertility rate
$$ GFR = 1000 \cdot \frac{\sum births}{\sum _{x=15}^{49} women}$$

```{r}
fem <- 
  kor |> 
  filter(sex == "female") |> 
  select(age, exposure)
births <-
  kor |> 
  filter(sex == "total") |> 
  select(age, births)

gfr <-
  full_join(fem, 
            births, 
            by = join_by(age)) |> 
  filter(between(x = age, left = 15, right = 49)) |> 
  summarize(B = sum(births),
            E = sum(exposure)) |> 
  mutate(GFR = 1000 * B / E)
gfr

```

# Age-specific fertility rates
 Now, GFR beats CBR in terms of signal clarity, but we can do far better: note age structures can still vary greatly within the 35-year span that GFR is calculated over, and so you can't really even calculate the GFR series for a given country and interpret it directly... It might covary with CBR. It might covary with TFR. But it is a biased signal nonetheless.
$$ ASFR = F_x =\frac{births_x}{exposure_x}$$

To do this: pipe the joined data into `mutate()` to create the fertility rates column, and then optionally filter to rows where fertility (births) > 0
```{r}
fert <- 
 full_join(fem, 
            births, 
            by = join_by(age)) |> 
  mutate(fx = births / exposure) |> 
  filter(fx > 0)
# View(fert)
```

# Visualize fertiltiy rates

```{r}
fert |> 
  ggplot(mapping = aes(x = age,
                       y = fx)) +
  geom_line(color = "red", linewidth = 2, alpha = .5) +
  theme_minimal()
```
# TFR
The total fertility rate is the sum of the age-specific fertility rates in a period. 

```{r}
fert |> 
  summarize(tfr = sum(fx))
```
It is not a projection (and by extension not a forecast); It is NOT a perfect benchmark for actual fertility conditions, due to further uncontrolled heterogeneity in aspects of population structure beyond age.

# Age-specific mortality rates

```{r, warning=FALSE}
kor |> 
  mutate(mx = deaths / exposure) |> 
  ggplot(mapping = aes(x = age,
                       y = mx,
                       color = sex)) +
  geom_line() +
  scale_y_log10()
```



# Exercises: Read in Chad fertility inputs
Data submitted by Yewande Odia :-)

In this data, births are average per 1000 women years 2010-2014, so we want to calculate metrics for the whole period 2010-2014. Populations are given for 2010 and 2015
1. CBR 
2. ASFR
3. TFR

```{r}
chad <- read_csv("Data/chad_fertility.csv", show_col_types = FALSE)

# CBR
chad |> 
  mutate(Exposure = (Total_2010 + Total_2015)*2.5) |> 
  summarize(B = sum(Births),
            E = sum(Exposure)) |> 
  mutate(CBR = 1000 * B / E)
```

Age-specific fertility, in this case means the average rate experienced over a 5-year age interval. Remember to recalculate exposure, this time using female populations!
```{r}
# ASFR
asfr <- 
  chad |> 
  mutate(Exposure = (Females_2010 + Females_2015)/2 * 5,
         fx = Births / Exposure,
         Age = parse_number(Age)) |> 
  filter(fx > 0)

asfr |> 
  ggplot(mapping = aes(x = Age, y = fx)) +
  geom_line()
```

# TFR
Since each rate covers 5 single-age groups, we need to multiply by 5!
```{r}
asfr |> 
  summarize(TFR = sum(fx) * 5)
```
This estimate covers the period 2010-2015; we don't know strictly whether this is a 5-year period or 6-year period. You can compare with external estimates to see how close this one is.

# Back-of-the-envelope life expectancy?

As you'll surely see an the event-history course, survivorship $\ell(x)$ can be calculated as:
$$\ell(x) = e^{-H(x)}$$
where H is the cumulative hazard, which in our case we approximate with $m(x)$, which is a step function with tiny single-age steps. Then the sum of survivorship is the expectancy. We down-adjust half an interval just to account for the discrete nature of the data.

```{r}
mx <- 
  kor |> 
  mutate(mx = deaths / exposure) |> 
  filter(sex == "female") |> 
  pull(mx)
mx <- c(0,mx)

lx_hat <- exp(-cumsum(mx))
sum(lx_hat) - .5
```


